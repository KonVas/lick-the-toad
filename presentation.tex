% Created 2023-10-11 Wed 12:33
% Intended LaTeX compiler: pdflatex
\documentclass[bigger]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usetheme{CambridgeUS}
\usecolortheme{default}
\author{Konstantinos Vasilakos}
\date{\today}
\title{Intelligent Behemoths}
\institute{konvas.netlify.app/}
\hypersetup{
 pdfauthor={Konstantinos Vasilakos},
 pdftitle={Intelligent Behemoths},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.2 (Org mode 9.7)}, 
 pdflang={English}}
\begin{document}

\maketitle
\begin{frame}{Outline}
\tableofcontents
\end{frame}

\section{Overview}
\label{sec:org9b6ad11}
\begin{frame}[label={sec:org9ee4110}]{The System}
The system is an interface to generate data using the X Y coordinates of touch screen which simply pushes a spherical object while interacting with the other users in the network. On second stage, it support the prediction of the input data using a neural network module by ML5. It also lets the user to create sound synthesis on their mobile device and computer and send this sonic event data for further processing.
\end{frame}
\begin{frame}[label={sec:orgb4c1f64}]{Data}
The data is stored in the system, and used from training of the neural network.
The model is providing predictions based on the previous data generated
by each user. While the predictions are based on the human input the output
values are transformed to sound illustrating the interactivity between the users.
\end{frame}
\begin{frame}[label={sec:org5ae3425}]{The Idea}
This places the members of the audience at the forefront of the music making.
It allows them to conrol the output and trigger their own sounds in the device,
or send their information to further processing.
\end{frame}
\begin{frame}[label={sec:orgfd61a8e}]{Sound}
The live coding performance is focussing on the real time sonification of the incoming data.
Each user is transmitting the information of their sound synthesis in SuperCollider.
The coder is mapping this values in running processes with the help of streams and patterns
of SuperCollider.
\end{frame}
\begin{frame}[label={sec:org24a08d4}]{Live Coding Method}
Patterns, are random or sequential, which may control any sound parameter of a synthesiser.
Examples, Prand, Pseq, Pser, Pxrand etc. The input data can also be used as single values.
\end{frame}
\begin{frame}[label={sec:orgceef018}]{The aftermath}
The project aims to serve as a visual map which delineates the actions of the members of an audience trying to make sense of an uncharted territory with limited spatial movements. At second level, the sound that is created is the representation of their palpitations. These are used as the stimuli of the predictions which is sonified in real time independently forming a dynamic soundscape; an unpredictable sound result generated by the algorithm that is trying to connect the gaps by drawing proximal values between X and Y coordinates of a music stage which is shaoed while the performance is at run. While the human agency is paradoxically in control of a musical performance previously implausible, a large amount of unpredictabiltiy is inevitable, the input serves as the seeding input for a larger chain of processing and interconnection of modules, such as the Markovian chains and the machine learning modules bound together to offer a great paradox of a calculated surprise at the cost of compromising the reproducibility of the musical outcome.
\end{frame}
\begin{frame}[label={sec:orga79941c}]{Epilogue}
Such causes however are not flaws but main features of the craft of electroacoustic music. In other words, to botch a quote by Xenakis, ``A new and rich work of visual art could arise, whose evolution would be ruled by huge computers (tools vital not only for the calculation of bombs or price indexes, but also for the artistic life of the future), a total audiovisual manifestation ruled in its compositional intelligence by machines serving other machines, which are, thanks to the scientific arts, directed by man.'' Formalized Music (1971), Bloomington Indiana Press.
\end{frame}
\begin{frame}[label={sec:org6d2cacb}]{Technical Details}
\begin{itemize}
\item Project is a client/server system
\begin{itemize}
\item Training interface and Predictions.
\end{itemize}
\item The project is developed in JavaScript.
\item Communication client/server is bound through WebSockets.
\item Server is made using Express.
\item Data from clients is sent through OSC protocol.
\item It is hosted locally with NodeJS computer and online -> \url{https://lick-the-toad.netlify.app/}
\item Connection with users and OSC is supported only locally now.
\item Sound synthesis of clients is using Tone.js and Markov chains extension for JS.
\end{itemize}
\end{frame}
\end{document}