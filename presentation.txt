Konstantinos Vasilakos


Table of Contents
─────────────────

1. Presentation
.. 1. The System
.. 2. Data
.. 3. The Idea
.. 4. Sound
..... 1. Live Coding Method
.. 5. The aftermath
.. 6. Technical Details


1 Presentation
══════════════

1.1 The System
──────────────

  The system is an interface to generate data using the X Y coordinates
  of touch screen which simply pushes a spherical object while
  interacting with the other users in the network.


1.2 Data
────────

  The data is stored in the system, and used from training of the neural
  network. The model is providing predictions based on the previous data
  generated by each user. While the predictions are based on the human
  input the output values are transformed to sound illustrating the
  interactivity between the users.


1.3 The Idea
────────────

  This places the members of the audience at the forefront of the music
  making. It allows them to conrol the output and trigger their own
  sounds in the device, or send their information to further processing.


1.4 Sound
─────────

  The live coding performance is focussing on the real time sonification
  of the incoming data. Each user is transmitting the information of
  their sound synthesis in SuperCollider. The coder is mapping this
  values in running processes with the help of streams and patterns of
  SuperCollider.


1.4.1 Live Coding Method
╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌

  Patterns, are random or sequential, which may control any sound
  parameter of a synthesiser. Examples, Prand, Pseq, Pser, Pxrand etc.
  The input data can also be used as single values.


1.5 The aftermath
─────────────────

  The project aims to serve as a visual map which delineates the actions
  of the members of an audience trying to make sense of an uncharted
  territory with limited spatial movements. At second level, the sound
  that is created is the representation of their palpitations. These are
  used as the stimuli of the predictions which is sonified in real time
  independently forming a dynamic soundscape; an unpredictable sound
  result generated by the algorithm that is trying to connect the gaps
  by drawing proximal values between X and Y coordinates of a music
  stage which is shaoed while the performance is at run. While the human
  agency is paradoxically in control of a musical performance previously
  implausible, a large amount of unpredictabiltiy is inevitable, the
  input serves as the seeding input for a larger chain of processing and
  interconnection of modules, such as the Markovian chains and the
  machine learning modules bound together to offer a great paradox of a
  calculated surprise at the cost of compromising the reproducibility of
  the musical outcome. Such causes however are not flaws but main
  features of the craft of electroacoustic music. In other words, to
  botch a quote by Xenakis, “A new and rich work of visual art could
  arise, whose evolution would be ruled by huge computers (tools vital
  not only for the calculation of bombs or price indexes, but also for
  the artistic life of the future), a total audiovisual manifestation
  ruled in its compositional intelligence by machines serving other
  machines, which are, thanks to the scientific arts, directed by man.”


1.6 Technical Details
─────────────────────

  ⁃ Project is a client/server system
    ⁃ Training interface and Predictions.
  ⁃ The project is developed in JavaScript.
  ⁃ Communication client/server is bound through WebSockets.
  ⁃ Server is made using Express.
  ⁃ Data from clients is sent through OSC protocol.
  ⁃ It runs on NodeJS in my computer but also online ->
  ⁃ Connection with users is supported only locally now.
  ⁃ Sound synthesis of clients is using Tone.js and Markov chains
    extension for JS.
