#+TITLE:    Intelligent Beheamoths: live coding with Ltt
#+SUBTITLE: CEAM  Conference, Moscow Conservatory Oct. 2023
#+AUTHOR:    Konstantinos Vasilakos
#+EMAIL:     konstantinos.vasilakos@gmail.com
#+DATE:      2023-10-23
DESCRIPTION: Live coding with networked music system using Neural Network's regression algorithm trained by multiple users and sonified using SuperCollider's custom made sound synthesis modules.
- For a full explanation of the system see this link: https://nime.pubpub.org/pub/lick-the-toad-konvas-nime2021/release/1
 - An online deployment of the interface to experiment is hosted at this link https://lick-the-toad.netlify.app/
#+KEYWORDS:
#+LANGUAGE:  en
#+BEAMER_THEME: Rochester [height=20pt]
#+OPTIONS:   H:2 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:https://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+BEAMER_COLOR_THEME: seahorse
#+HTML_LINK_UP:
#+HTML_LINK_HOME:
#+startup: beamer
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [t, 10pt, seahorse, bigger]
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)

* The Idea
** The Interface
#+BEGIN_CENTER
#+caption: Ltt interface and control GUI.
[[./screens/ltt-interface.png]]
#+END_CENTER

* Development
** Technical Details
- Project is a client/server system encapsulating training/predictions.
- Communication client/server is bound through WebSockets, and Express server.
- Data from clients is using OSCJS library.
- It is hosted locally with NodeJS and online -> https://lick-the-toad.netlify.app/
 - Connection with users and OSC is supported only locally now.
- Sound synthesis of clients is using Tone.js and Markov chains extension for JS.


* Interaction
** Selection of Data on the Fly
SuperCollider's part of the system supports selection of each event through the user's ID in a GUI.
#+BEGIN_CENTER
#+ATTR_LaTeX: :height 0.5\textwidth :center
[[./screens/sc-pop-up.png]]
#+ATTR_LaTeX: :height 0.5\textwidth :center
[[./screens/sc-sliders.png]]
#+END_CENTER

* Network Interaction
** Interoperabillity
@@beamer:[ "A0", "C4", "C4", "A0", "G2", "G2", "A0", "G2" ]@@
@@beamer:OSC:[ "214.00", "601.00", "601.00", "214.00", "428.00", "428.00", "214.00", "428.00" ]@@

The performance is shaped by the data of each user which is interpreted live while the performance unfolds. This way the sounds both from the decentralized domain of the user's together with the live electronics are creating an unpredictable sonic environment which enables the communication between audience and performer.

- Since the live coding process allows for changing the state of the performance "instruments" on the fly, the results can be indeterministic and allow for a wide range of sound outcomes.
  - For this, a plethora of idiomatic interpretation of data to sound is viable, since data is agnostic to music genre and/or textural composition.

* Sound Making
** Performance Events Patterns and Streams in SC
Performance elaborates using Patterns as random or sequential streams, and mapped to any sound parameter:
Examples of patterns include:
$Prand, Pseq, Pser, Pxrand$
and more...

- The live coding performance is focussing on the real time sonification of the incoming data.
- Each user is sending their data in an array of notes.
- The coder is mapping this values in running processes with the help of streams and patterns of SuperCollider.

#+BEGIN_SRC sclang :noeval
Pdef(\user_ID,
	Pbind(\dur, 0.1,
		\freq, Pseq([121.0, 220.0, 340.0, 280], inf)
	));
#+END_SRC

* Control from SC
** SC OSC Interface
A small command line is also available from SC to set all users' new states of the Markov chain and trigger back new data. The lines below allow the real time communication with the users interfaces. It triggers the training and the loopback of new data in performer's OSC client.
#+BEGIN_SRC sclang :noeval
n=NetAddr("localhost", 57122);
n.sendMsg('/kv', "markov_train");
n.sendMsg('/kv', "osc_trigger");
#+END_SRC

* Demo
** Demo.
Live coding in SC -> play some now...
#+ATTR_LaTeX: :height 1.0\textwidth :center
[[./screens/live-coding.png]]

* Reflections
** Discussion
The project aims to serve as an interconnector between coder and audience:

- Incoming data is the stimuli for real time arbitrary sonifications forming a dynamic soundscape.

- An unpredictable sound result generated by the algorithm that is trying to connect the gaps by sending proximal values between X and Y coordinates from the user's device.

- The input serves as the seeding input for a larger chain of processing and interconnection of modules, such as the Markovian chains and the machine learning modules bound together to offer a great paradox of a calculated surprise of unpredictable sonifications.

- Performer(s) and audience is cooperating throughtout the performance.

* Final Remarks
** Feedback
Thank you!

+ You may provide your feedback at konstantinos.vasilakos@gmail.com
